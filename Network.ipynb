{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebd7ff9-b64d-4300-a90f-91709e017cb6",
   "metadata": {},
   "source": [
    "# HW 1 - Building a network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653560dd-b61c-4ab1-a9d7-6465bc2d8e9f",
   "metadata": {},
   "source": [
    "* x1, x2, x3 = (1, 2, -1)\n",
    "* Weights have been initated with 1. value\n",
    "* Biases have been initated with 0 value\n",
    "* The reuqired network must include 2 hidden layers, with 2 neurons in each layer\n",
    "* One dimension output layer\n",
    "* true y value = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f379af-803f-458c-ada3-ca9ed8d6cd0e",
   "metadata": {},
   "source": [
    "# Loading required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc4caa-197f-4349-a802-b99d4da8eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239edf23-9d26-4e9c-89de-a2f41b7d6000",
   "metadata": {},
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dcaee7ab-e6f0-4b9e-b438-b6838b91ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.clip(x, 0, None)\n",
    "\n",
    "def d_ReLU(x):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def loss(y_pred: npt.ArrayLike, y_true: npt.ArrayLike):\n",
    "    return ((y_pred - y_true) ** 2).mean()\n",
    "\n",
    "def d_loss(y_pred: npt.ArrayLike, y_true: npt.ArrayLike):\n",
    "    n = y_true.shape[0]\n",
    "    gradient = 2. * (y_pred - y_true) / n\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800748b4-5c20-4d82-9460-95e678f2bab6",
   "metadata": {},
   "source": [
    "# The *Layer* class - OOP\n",
    "\n",
    " * The learning rate is set to 0.01\n",
    " * The activation function is ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "57b6da75-6594-4673-a86a-a38b2cb8adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    activationFunctions = {\n",
    "        'ReLU': (ReLU, d_ReLU)\n",
    "    }\n",
    "    \n",
    "    lr = 0.1\n",
    "    \n",
    "    def __init__(self, neurons: int, inputs: int, activation: str = 'ReLU'):\n",
    "        \"\"\"\n",
    "        The layer instance should be initiated with the input count and number of neurons.\n",
    "        \"\"\"\n",
    "        self.W = np.ones((neurons, inputs))\n",
    "        self.b = np.zeros((neurons, 1))\n",
    "        self.act, self.d_act = self.activationFunctions.get(activation)\n",
    "        \n",
    "    def forward(self, A_prev: npt.ArrayLike) -> npt.ArrayLike:\n",
    "        \"\"\"\n",
    "        Each forward step will calculate the next layer neurin as a function of its prev input and current \n",
    "        weight dot product, on top of that, the activation function will be applied.\n",
    "        \"\"\"\n",
    "        self.A_prev = A_prev\n",
    "        self.Z = np.dot(self.W, self.A_prev) + self.b\n",
    "        self.A = self.act(self.Z)\n",
    "        return self.A\n",
    "        \n",
    "    def backprop(self, dA: npt.ArrayLike) -> npt.ArrayLike:\n",
    "        dZ = np.multiply(self.d_act(self.Z), dA)\n",
    "        dW = 1/dZ.shape[1] * np.dot(dZ, self.A_prev.T)\n",
    "        db = 1/dZ.shape[1] * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(self.W.T, dZ)\n",
    "        \n",
    "        self.W = self.W - self.lr * dW\n",
    "        self.b = self.b - self.lr * db\n",
    "        \n",
    "        return dA_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f8e3f25c-db80-420f-a135-d69e1cd10109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: \n",
      " \n",
      "**************************************************\n",
      "Layer 0: \n",
      " [[2.]\n",
      " [2.]]\n",
      "Layer 1: \n",
      " [[4.]\n",
      " [4.]]\n",
      "Layer 2: \n",
      " [[8.]]\n",
      "Epoch Cost 0: \n",
      " 64.0\n",
      "Backprop 0: \n",
      " \n",
      "Backprop 1: \n",
      " \n",
      "Backprop 2: \n",
      " \n",
      "Final reaults\n",
      "\n",
      "Weight: [[ 4.2  7.4 -2.2]\n",
      " [ 4.2  7.4 -2.2]]\n",
      "Biases: [[3.2]\n",
      " [3.2]]\n"
     ]
    }
   ],
   "source": [
    "def logit(index, text, value = None, add_sep: bool = False):\n",
    "    print(f\"{text} {index}: \\n {value if value is not None else ''}\")\n",
    "    if add_sep:\n",
    "        print(f\"{'*'*50}\")\n",
    "\n",
    "# Given inputs\n",
    "\n",
    "x_train = np.array([[1.0], [2.0], [-1.0]])\n",
    "y_train = np.array([[0]]) \n",
    "\n",
    "m = 1\n",
    "epochs = 1\n",
    "\n",
    "layers = [Layer(2, 3, 'ReLU'), Layer(2, 2, 'ReLU'), Layer(1, 2, 'ReLU')]\n",
    "costs = []\n",
    "\n",
    "for i, epoch in enumerate(range(epochs)):\n",
    "    logit(i, \"Epoch\", add_sep=True)\n",
    "    # FORWARD\n",
    "    A = x_train\n",
    "    for j, layer in enumerate(layers):\n",
    "        A = layer.forward(A)\n",
    "        logit(j, \"Layer\", A)\n",
    "    \n",
    "    # COSTS\n",
    "    cost = loss(y_train, A)\n",
    "    logit(i, \"Epoch Cost\", cost)\n",
    "    costs.append(cost)\n",
    "    \n",
    "    # BACKPROP\n",
    "    dA = d_loss(y_train, A)\n",
    "    for k, layer in enumerate(reversed(layers)):\n",
    "        dA = layer.backprop(dA)\n",
    "        logit(k, \"Backprop\")\n",
    "\n",
    "print(f\"Final param values:\\n\")\n",
    "print(f\"Weight: {layer.W}\")\n",
    "print(f\"Biases: {layer.b}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
